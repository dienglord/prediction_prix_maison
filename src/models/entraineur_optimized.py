import pandas as pd
import numpy as np
import logging
from pathlib import Path
import sys
import joblib
from typing import Dict, Any, Tuple
import warnings
from datetime import datetime
import os
warnings.filterwarnings('ignore')

# MLflow imports (optionnel)
try:
    import mlflow
    import mlflow.sklearn
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False
    print("âš ï¸ MLflow non disponible - fonctionnement sans tracking")

# ModÃ¨les ML - SEULEMENT LINEAR REGRESSION
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score

# Configuration centralisÃ©e
sys.path.append(str(Path(__file__).resolve().parents[2]))
from src.config.gestionnaire_config import get_config_manager

class EntraineurOptimise:
    """
    EntraÃ®neur optimisÃ© - SEULEMENT Linear Regression (le meilleur modÃ¨le).
    Version GitHub optimisÃ©e.
    """
    
    def __init__(self, environment: str = None):
        # DÃ©terminer l'environnement
        self.environment = environment or os.getenv('MLOPS_ENV', 'development')
        
        # Charger la configuration
        self.config_manager = get_config_manager(self.environment)
        self.config = self.config_manager.config
        
        if not self.config:
            raise ValueError(f"Impossible de charger la configuration pour: {self.environment}")
        
        # Configuration du projet
        self.racine_projet = self.config_manager.project_root
        
        # Configuration du logging
        self.setup_logging()
        
        # Configuration MLflow (optionnelle)
        if MLFLOW_AVAILABLE:
            self.setup_mlflow()
        
        # CrÃ©er SEULEMENT le modÃ¨le Linear Regression
        self.modele_config = self.create_linear_regression_model()
        
        # Stockage des rÃ©sultats
        self.modele_final = None
        self.metriques_finales = None
        
        self.logger.info(f"ğŸ”¥ EntraÃ®neur optimisÃ© - Environnement: {self.environment}")
        self.logger.info(f"ğŸ“Š ModÃ¨le unique: Linear Regression (le meilleur)")
        self.logger.info(f"ğŸ¯ Version GitHub optimisÃ©e")
    
    def setup_logging(self):
        """Configure le systÃ¨me de logging depuis la configuration."""
        logs_dir = self.racine_projet / self.config.logging.file_path
        logs_dir.mkdir(exist_ok=True)
        
        # Configuration du niveau de logging
        level = getattr(logging, self.config.logging.level.upper())
        
        # Logger simple pour version optimisÃ©e
        logging.basicConfig(
            level=level,
            format=self.config.logging.format,
            handlers=[
                logging.FileHandler(logs_dir / f"training_{self.environment}.log", encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ],
            force=True
        )
        
        self.logger = logging.getLogger(f"entraineur_optimise_{self.environment}")
    
    def setup_mlflow(self):
        """Configure MLflow depuis la configuration (optionnel)."""
        if not MLFLOW_AVAILABLE:
            return
            
        try:
            # Configuration MLflow lÃ©gÃ¨re
            mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)
            
            # CrÃ©er ou utiliser l'expÃ©rience
            try:
                mlflow.set_experiment(self.config.mlflow.experiment_name)
                self.logger.info(f"âœ… MLflow configurÃ©: {self.config.mlflow.experiment_name}")
            except Exception as exp_error:
                self.logger.warning(f"âš ï¸ MLflow expÃ©rience: {str(exp_error)}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ MLflow indisponible: {str(e)}")
            self.MLFLOW_AVAILABLE = False
    
    def create_linear_regression_model(self) -> Dict[str, Any]:
        """CrÃ©e SEULEMENT le modÃ¨le Linear Regression optimisÃ©."""
        
        # Configuration manuelle optimisÃ©e pour Linear Regression
        model_config = {
            'algorithm': 'LinearRegression',
            'hyperparameters': {
                'fit_intercept': True
                # normalize supprimÃ© (obsolÃ¨te dans scikit-learn rÃ©cent)
            },
            'description': 'Linear Regression - Meilleur modÃ¨le (RÂ² = 0.4924)',
            'performance': {
                'r2_test': 0.4924,
                'rmse_test': 253409.77,
                'training_time': 0.01
            }
        }
        
        # CrÃ©er le modÃ¨le
        modele = LinearRegression(**model_config['hyperparameters'])
        
        modele_info = {
            'model': modele,
            'config': model_config,
            'name': 'linear_regression'
        }
        
        self.logger.info(f"âœ… ModÃ¨le Linear Regression crÃ©Ã©")
        self.logger.info(f"ğŸ“Š HyperparamÃ¨tres: {model_config['hyperparameters']}")
        
        return modele_info
    
    def charger_donnees_preprocessees(self) -> Tuple[pd.DataFrame, ...]:
        """Charge les donnÃ©es prÃ©processÃ©es depuis la configuration."""
        self.logger.info("ğŸ“Š Chargement des donnÃ©es prÃ©processÃ©es...")
        
        processed_dir = self.racine_projet / self.config.data.processed_path
        
        try:
            X_train = pd.read_csv(processed_dir / "X_train.csv")
            X_val = pd.read_csv(processed_dir / "X_val.csv")
            X_test = pd.read_csv(processed_dir / "X_test.csv")
            y_train = pd.read_csv(processed_dir / "y_train.csv").iloc[:, 0]
            y_val = pd.read_csv(processed_dir / "y_val.csv").iloc[:, 0]
            y_test = pd.read_csv(processed_dir / "y_test.csv").iloc[:, 0]
            
            self.logger.info(f"âœ… DonnÃ©es chargÃ©es:")
            self.logger.info(f"   - Train: {X_train.shape}")
            self.logger.info(f"   - Validation: {X_val.shape}")
            self.logger.info(f"   - Test: {X_test.shape}")
            self.logger.info(f"   - Features: {len(X_train.columns)}")
            
            return X_train, X_val, X_test, y_train, y_val, y_test
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur lors du chargement: {str(e)}")
            raise
    
    def calculer_metriques(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """Calcule les mÃ©triques de performance."""
        metriques = {
            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
            'mae': mean_absolute_error(y_true, y_pred),
            'r2': r2_score(y_true, y_pred),
            'mape': np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100
        }
        
        return metriques
    
    def entrainer_modele_optimise(self, X_train: pd.DataFrame, y_train: pd.Series,
                                 X_val: pd.DataFrame, y_val: pd.Series) -> Dict[str, Any]:
        """EntraÃ®ne le modÃ¨le Linear Regression avec tracking optionnel."""
        
        modele = self.modele_config['model']
        config = self.modele_config['config']
        
        self.logger.info("ğŸ”¥ === ENTRAÃNEMENT LINEAR REGRESSION OPTIMISÃ‰ ===")
        
        # MLflow run optionnel
        if MLFLOW_AVAILABLE:
            run_name = f"linear_regression_{self.environment}_{datetime.now().strftime('%H%M%S')}"
            try:
                mlflow.start_run(run_name=run_name)
                self.logger.info(f"ğŸ“Š MLflow Run dÃ©marrÃ©")
            except:
                self.logger.warning("âš ï¸ MLflow run Ã©chouÃ© - continue sans tracking")
        
        try:
            # === ENTRAÃNEMENT ===
            start_time = datetime.now()
            modele.fit(X_train, y_train)
            training_time = (datetime.now() - start_time).total_seconds()
            
            self.logger.info(f"âœ… EntraÃ®nement terminÃ© en {training_time:.3f}s")
            
            # === PRÃ‰DICTIONS ===
            y_pred_train = modele.predict(X_train)
            y_pred_val = modele.predict(X_val)
            
            # === MÃ‰TRIQUES ===
            metriques_train = self.calculer_metriques(y_train, y_pred_train)
            metriques_val = self.calculer_metriques(y_val, y_pred_val)
            
            # Validation croisÃ©e
            cv_scores = cross_val_score(modele, X_train, y_train, cv=5, 
                                      scoring='neg_mean_squared_error')
            cv_rmse = np.sqrt(-cv_scores)
            
            # Ã‰cart train/validation (overfitting check)
            ecart_r2 = metriques_train['r2'] - metriques_val['r2']
            
            # === LOGGING OPTIONNEL MLFLOW ===
            if MLFLOW_AVAILABLE:
                try:
                    mlflow.log_param("environment", self.environment)
                    mlflow.log_param("algorithm", "LinearRegression")
                    mlflow.log_params(config['hyperparameters'])
                    
                    mlflow.log_metric("train_r2", metriques_train['r2'])
                    mlflow.log_metric("val_r2", metriques_val['r2'])
                    mlflow.log_metric("val_rmse", metriques_val['rmse'])
                    mlflow.log_metric("cv_rmse_mean", cv_rmse.mean())
                    mlflow.log_metric("training_time", training_time)
                    mlflow.log_metric("overfitting_gap", ecart_r2)
                    
                    mlflow.set_tag("model_type", "linear_regression")
                    mlflow.set_tag("optimized_version", "github")
                    mlflow.set_tag("best_model", "true")
                    
                    mlflow.end_run()
                    self.logger.info("ğŸ“Š MÃ©triques MLflow enregistrÃ©es")
                except Exception as mlflow_error:
                    self.logger.warning(f"âš ï¸ MLflow logging Ã©chouÃ©: {mlflow_error}")
            
            # === AFFICHAGE CONSOLE ===
            self.logger.info("âœ… === RÃ‰SULTATS LINEAR REGRESSION ===")
            self.logger.info(f"ğŸ“Š RÂ² validation: {metriques_val['r2']:.4f}")
            self.logger.info(f"ğŸ“Š RMSE validation: {metriques_val['rmse']:.2f}")
            self.logger.info(f"ğŸ“Š MAE validation: {metriques_val['mae']:.2f}")
            self.logger.info(f"ğŸ“Š CV RMSE: {cv_rmse.mean():.2f} Â± {cv_rmse.std():.2f}")
            self.logger.info(f"ğŸ“Š Temps entraÃ®nement: {training_time:.3f}s")
            self.logger.info(f"ğŸ“Š Ã‰cart train/val: {ecart_r2:.4f}")
            
            # Performance check
            performance_ok = (
                metriques_val['r2'] > 0.4 and 
                metriques_val['rmse'] < 300000 and
                training_time < 10
            )
            
            self.logger.info(f"ğŸ“Š Performance OK: {performance_ok}")
            
            # PrÃ©parer les rÃ©sultats
            resultats = {
                'modele': modele,
                'nom': 'linear_regression',
                'metriques_train': metriques_train,
                'metriques_val': metriques_val,
                'cv_rmse_mean': cv_rmse.mean(),
                'cv_rmse_std': cv_rmse.std(),
                'ecart_r2': ecart_r2,
                'training_time': training_time,
                'performance_ok': performance_ok,
                'y_pred_train': y_pred_train,
                'y_pred_val': y_pred_val
            }
            
            return resultats
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur entraÃ®nement: {str(e)}")
            if MLFLOW_AVAILABLE:
                try:
                    mlflow.end_run(status="FAILED")
                except:
                    pass
            raise
    
    def evaluer_sur_test(self, X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, float]:
        """Ã‰value le modÃ¨le sur le set de test."""
        if self.modele_final is None:
            raise ValueError("Aucun modÃ¨le n'a Ã©tÃ© entraÃ®nÃ©")
        
        self.logger.info("ğŸ¯ === Ã‰VALUATION FINALE SUR TEST ===")
        
        # PrÃ©dictions sur le test
        y_pred_test = self.modele_final.predict(X_test)
        metriques_test = self.calculer_metriques(y_test, y_pred_test)
        
        # Logging MLflow optionnel
        if MLFLOW_AVAILABLE:
            try:
                with mlflow.start_run(run_name=f"test_evaluation_{self.environment}"):
                    mlflow.log_param("environment", self.environment)
                    mlflow.log_param("model_type", "linear_regression")
                    mlflow.log_param("evaluation_type", "final_test")
                    
                    mlflow.log_metric("test_rmse", metriques_test['rmse'])
                    mlflow.log_metric("test_mae", metriques_test['mae'])
                    mlflow.log_metric("test_r2", metriques_test['r2'])
                    
                    mlflow.set_tag("final_evaluation", "true")
                    mlflow.set_tag("optimized_version", "github")
            except Exception as e:
                self.logger.warning(f"âš ï¸ MLflow test logging Ã©chouÃ©: {str(e)}")
        
        # Calcul de l'Ã©cart validation/test (gÃ©nÃ©ralisation)
        r2_val = self.metriques_finales['metriques_val']['r2']
        ecart_val_test = r2_val - metriques_test['r2']
        
        self.logger.info(f"ğŸ“Š === RÃ‰SULTATS FINAUX ===")
        self.logger.info(f"ğŸ“Š RÂ² test: {metriques_test['r2']:.4f}")
        self.logger.info(f"ğŸ“Š RMSE test: {metriques_test['rmse']:.2f}")
        self.logger.info(f"ğŸ“Š MAE test: {metriques_test['mae']:.2f}")
        self.logger.info(f"ğŸ“Š Ã‰cart val/test: {ecart_val_test:.4f}")
        
        # Ã‰valuation de la gÃ©nÃ©ralisation
        if abs(ecart_val_test) < 0.05:
            self.logger.info("âœ… Excellente gÃ©nÃ©ralisation !")
        elif abs(ecart_val_test) < 0.10:
            self.logger.info("âœ… Bonne gÃ©nÃ©ralisation")
        else:
            self.logger.warning("âš ï¸ GÃ©nÃ©ralisation Ã  surveiller")
        
        return metriques_test
    
    def sauvegarder_modele_optimise(self) -> Path:
        """Sauvegarde le modÃ¨le Linear Regression optimisÃ©."""
        if self.modele_final is None:
            raise ValueError("Aucun modÃ¨le Ã  sauvegarder")
        
        models_dir = self.racine_projet / "models"
        models_dir.mkdir(exist_ok=True)
        
        # Nom de fichier optimisÃ©
        nom_fichier = f"modele_linear_regression_{self.environment}.pkl"
        chemin_sauvegarde = models_dir / nom_fichier
        
        # DonnÃ©es optimisÃ©es Ã  sauvegarder
        donnees_modele = {
            'modele': self.modele_final,
            'nom_modele': 'linear_regression',
            'environment': self.environment,
            'metriques_test': self.metriques_finales.get('metriques_test', {}),
            'hyperparameters': self.modele_config['config']['hyperparameters'],
            'performance': self.modele_config['config']['performance'],
            'timestamp': datetime.now().isoformat(),
            'version': "2.0_github_optimized",
            'description': "ModÃ¨le Linear Regression optimisÃ© - Meilleur performance",
            'optimization_info': {
                'original_models': 3,
                'kept_models': 1,
                'reason': 'GitHub size optimization',
                'space_saved': '95%',
                'performance_impact': 'None - best model kept'
            }
        }
        
        joblib.dump(donnees_modele, chemin_sauvegarde)
        
        self.logger.info(f"âœ… ModÃ¨le sauvegardÃ©: {chemin_sauvegarde}")
        self.logger.info(f"ğŸ“¦ Taille fichier: {chemin_sauvegarde.stat().st_size / 1024:.1f} KB")
        
        return chemin_sauvegarde
    
    def entrainer_pipeline_complet(self):
        """Pipeline d'entraÃ®nement complet optimisÃ©."""
        self.logger.info("ğŸš€ === PIPELINE ENTRAÃNEUR OPTIMISÃ‰ ===")
        
        try:
            # 1. Charger les donnÃ©es
            self.logger.info("ğŸ“Š 1. Chargement des donnÃ©es...")
            X_train, X_val, X_test, y_train, y_val, y_test = self.charger_donnees_preprocessees()
            
            # 2. EntraÃ®ner Linear Regression
            self.logger.info("ğŸ”¥ 2. EntraÃ®nement Linear Regression...")
            resultats = self.entrainer_modele_optimise(X_train, y_train, X_val, y_val)
            
            # Stocker les rÃ©sultats
            self.modele_final = resultats['modele']
            self.metriques_finales = resultats
            
            # 3. Ã‰valuation finale sur test
            self.logger.info("ğŸ¯ 3. Ã‰valuation finale sur test...")
            metriques_test = self.evaluer_sur_test(X_test, y_test)
            self.metriques_finales['metriques_test'] = metriques_test
            
            # 4. Sauvegarde
            self.logger.info("ğŸ’¾ 4. Sauvegarde du modÃ¨le...")
            chemin_modele = self.sauvegarder_modele_optimise()
            
            # 5. RÃ©sumÃ© final
            self.logger.info("âœ… === PIPELINE TERMINÃ‰ ===")
            self.logger.info(f"ğŸ† ModÃ¨le: Linear Regression")
            self.logger.info(f"ğŸ“Š RÂ² test: {metriques_test['r2']:.4f}")
            self.logger.info(f"ğŸ¯ RMSE test: {metriques_test['rmse']:.2f}")
            self.logger.info(f"ğŸ’¾ ModÃ¨le sauvÃ©: {chemin_modele.name}")
            self.logger.info(f"ğŸ”¥ Environnement: {self.environment}")
            self.logger.info(f"ğŸ¯ Version: GitHub optimisÃ©e")
            
            return {
                'success': True,
                'model_path': chemin_modele,
                'metrics': metriques_test,
                'model_name': 'linear_regression'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur pipeline: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }


def main():
    """Pipeline d'entraÃ®nement optimisÃ© - Linear Regression uniquement."""
    try:
        # RÃ©cupÃ©rer l'environnement
        import argparse
        parser = argparse.ArgumentParser(description="EntraÃ®nement optimisÃ© Linear Regression")
        parser.add_argument('--environment', '-e', default=None,
                           help='Environnement de configuration (development, production)')
        args = parser.parse_args()
        
        print("ğŸš€ === ENTRAÃNEUR OPTIMISÃ‰ GITHUB - LINEAR REGRESSION ===")
        print("ğŸ“Š Version allÃ©gÃ©e - Seulement le meilleur modÃ¨le")
        print("ğŸ¯ Ã‰conomie d'espace : ~95% (50MB â†’ 2MB)")
        print("=" * 60)
        
        # Initialiser l'entraÃ®neur optimisÃ©
        entraineur = EntraineurOptimise(environment=args.environment)
        
        print(f"\nğŸ“Š Configuration:")
        print(f"   - Environnement: {entraineur.environment}")
        print(f"   - Debug: {entraineur.config.debug}")
        print(f"   - ModÃ¨le unique: Linear Regression")
        print(f"   - Version: GitHub optimisÃ©e")
        
        # ExÃ©cuter le pipeline complet
        resultats = entraineur.entrainer_pipeline_complet()
        
        if resultats['success']:
            print(f"\nğŸ‰ === SUCCÃˆS ===")
            print(f"ğŸ† Meilleur modÃ¨le: {resultats['model_name']}")
            print(f"ğŸ“Š RÂ² test: {resultats['metrics']['r2']:.4f}")
            print(f"ğŸ¯ RMSE test: {resultats['metrics']['rmse']:.2f}")
            print(f"ğŸ’¾ ModÃ¨le sauvÃ©: {resultats['model_path'].name}")
            
            if MLFLOW_AVAILABLE and entraineur.config.mlflow.tracking_uri:
                print(f"\nğŸ“Š Pour voir MLflow UI:")
                print(f"mlflow ui --backend-store-uri {entraineur.config.mlflow.tracking_uri} --port 5000")
        else:
            print(f"\nâŒ === Ã‰CHEC ===")
            print(f"Erreur: {resultats['error']}")
            return None
        
        return entraineur
        
    except Exception as e:
        print(f"âŒ Erreur globale: {str(e)}")
        return None


if __name__ == "__main__":
    entraineur = main()